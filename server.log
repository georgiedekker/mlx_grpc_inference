2025-08-07 21:31:12,113 - INFO - ============================================================
2025-08-07 21:31:12,113 - INFO - WORKING MLX DISTRIBUTED INFERENCE
2025-08-07 21:31:12,113 - INFO - Using Python 3.13.5
2025-08-07 21:31:12,113 - INFO - Model: mlx-community/Qwen3-1.7B-8bit
2025-08-07 21:31:12,113 - INFO - ============================================================
2025-08-07 21:31:12,180 - INFO - ============================================================
2025-08-07 21:31:12,180 - INFO - WORKING MLX DISTRIBUTED INFERENCE
2025-08-07 21:31:12,180 - INFO - Using Python 3.13.5
2025-08-07 21:31:12,180 - INFO - Model: mlx-community/Qwen3-1.7B-8bit
2025-08-07 21:31:12,180 - INFO - ============================================================
2025-08-07 21:31:12,238 - INFO - ðŸš€ Rank 0/2 on mini1.local
2025-08-07 21:31:12,238 - INFO - Rank 0: Loading model mlx-community/Qwen3-1.7B-8bit...
2025-08-07 21:31:12,206 - INFO - ðŸš€ Rank 1/2 on mini2.local
2025-08-07 21:31:12,206 - INFO - Rank 1: Loading model mlx-community/Qwen3-1.7B-8bit...
Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]Fetching 9 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 224694.86it/s]
Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]Fetching 9 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9/9 [00:00<00:00, 128835.28it/s]
âœ… PATCHED: Qwen3Model.__call__ method replaced
2025-08-07 21:31:13,254 - INFO - Rank 0: Added pipeline support to model
2025-08-07 21:31:13,254 - INFO - Rank 0: Applying pipeline parallelism...
Rank 0: handling layers 14 to 27
2025-08-07 21:31:13,254 - INFO - Rank 0: Pipeline applied - processing assigned layers
2025-08-07 21:31:13,255 - INFO - Rank 0: Synchronizing...
2025-08-07 21:31:13,516 - INFO - Rank 1: Added pipeline support to model
2025-08-07 21:31:13,516 - INFO - Rank 1: Applying pipeline parallelism...
2025-08-07 21:31:13,516 - INFO - Rank 1: Pipeline applied - processing assigned layers
Rank 1: handling layers 0 to 13
2025-08-07 21:31:13,517 - INFO - Rank 1: Synchronizing...
2025-08-07 21:31:13,528 - INFO - Rank 1: Ready
2025-08-07 21:31:13,560 - INFO - Rank 0: Ready
2025-08-07 21:31:13,560 - INFO - ============================================================
2025-08-07 21:31:13,560 - INFO - âœ… DISTRIBUTED INFERENCE READY
2025-08-07 21:31:13,560 - INFO - âœ… Model: mlx-community/Qwen3-1.7B-8bit
2025-08-07 21:31:13,560 - INFO - âœ… Devices: 2 GPUs
2025-08-07 21:31:13,560 - INFO - âœ… Memory: 1.70 GB on rank 0
2025-08-07 21:31:13,560 - INFO - ============================================================
2025-08-07 21:31:13,528 - INFO - Worker rank 1 standing by
2025-08-07 21:31:13,561 - INFO - Starting API server on http://0.0.0.0:8100
[32mINFO[0m:     Started server process [[36m32220[0m]
[32mINFO[0m:     Waiting for application startup.
[32mINFO[0m:     Application startup complete.
[32mINFO[0m:     Uvicorn running on [1mhttp://0.0.0.0:8100[0m (Press CTRL+C to quit)
[32mINFO[0m:     127.0.0.1:54329 - "[1mGET /health HTTP/1.1[0m" [32m200 OK[0m
[32mINFO[0m:     127.0.0.1:54331 - "[1mGET /health HTTP/1.1[0m" [32m200 OK[0m
2025-08-07 21:31:24,035 - INFO - Generating 5 tokens from 9 prompt tokens
ðŸ”¥ RANK 0 (PID 32220): pipelined_call() executing with input shape (1, 9)
ðŸ“¥ RANK 0: Receiving from rank 1...
