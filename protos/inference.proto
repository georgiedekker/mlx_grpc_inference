syntax = "proto3";

package mlx_inference;

// Service for distributed inference
service InferenceService {
    // Process layers on this worker
    rpc ProcessLayers(LayerRequestV2) returns (LayerResponseV2);
    
    // Forward pass (for embeddings and final projection)
    rpc Forward(ForwardRequest) returns (ForwardResponse);
    
    // Health check
    rpc HealthCheck(HealthRequest) returns (HealthResponse);
    
    // Get device information
    rpc GetDeviceInfo(Empty) returns (DeviceInfo);
    
    // AllReduce for tensor parallelism
    rpc AllReduce(AllReduceRequest) returns (AllReduceResponse);
    
    // Initialize tensor parallel model shards
    rpc InitializeModelShard(ModelShardRequest) returns (ModelShardResponse);
}

// Empty message for requests without parameters
message Empty {}

// Device information
message DeviceInfo {
    string device_id = 1;
    string hostname = 2;
    int32 rank = 3;
    string role = 4;
    repeated int32 assigned_layers = 5;
    map<string, string> capabilities = 6;
    float gpu_utilization = 7;
    float memory_usage_gb = 8;
}

// Tensor message
message Tensor {
    bytes data = 1;
    repeated int64 shape = 2;
    string dtype = 3;
}

// Updated layer request to use Tensor with KV cache support
message LayerRequestV2 {
    Tensor input_tensor = 1;
    int32 start_layer = 2;
    int32 end_layer = 3;
    Tensor attention_mask = 4;  // Optional attention mask
    string session_id = 5;  // Session ID for KV cache
    bool is_prompt = 6;  // True for initial prompt, false for generation
    bool clear_cache = 7;  // Clear cache for this session
}

// Updated layer response to use Tensor
message LayerResponseV2 {
    Tensor output_tensor = 1;
}

// Forward request with KV cache support
message ForwardRequest {
    repeated int64 input_ids = 1;
    Tensor input_tensor = 2;
    bool is_embedding = 3;
    bool is_final_projection = 4;
    Tensor attention_mask = 5;  // Optional attention mask
    string session_id = 6;  // Session ID for KV cache
    bool is_prompt = 7;  // True for initial prompt, false for generation
}

// Forward response
message ForwardResponse {
    Tensor output = 1;
}

// Health check request/response
message HealthRequest {}

message HealthResponse {
    string status = 1;
    string message = 2;
}

// AllReduce operations for tensor parallelism
message AllReduceRequest {
    Tensor tensor = 1;
    string operation = 2;  // "SUM", "MEAN", "MAX", "MIN", "GATHER", "BROADCAST"
    string session_id = 3;
    int32 device_id = 4;
    int32 world_size = 5;
}

message AllReduceResponse {
    Tensor result_tensor = 1;
    string status = 2;
}

// Model sharding for tensor parallelism
message ModelShardRequest {
    int32 device_id = 1;
    int32 world_size = 2;
    string model_name = 3;
    map<string, Tensor> weight_shards = 4;  // layer_name -> weight tensor
}

message ModelShardResponse {
    string status = 1;
    string message = 2;
}