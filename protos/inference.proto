syntax = "proto3";

package mlx_inference;

// Service for distributed inference
service InferenceService {
    // Process layers on this worker
    rpc ProcessLayers(LayerRequestV2) returns (LayerResponseV2);
    
    // Forward pass (for embeddings and final projection)
    rpc Forward(ForwardRequest) returns (ForwardResponse);
    
    // Health check
    rpc HealthCheck(HealthRequest) returns (HealthResponse);
    
    // Get device information
    rpc GetDeviceInfo(Empty) returns (DeviceInfo);
}

// Empty message for requests without parameters
message Empty {}

// Device information
message DeviceInfo {
    string device_id = 1;
    string hostname = 2;
    int32 rank = 3;
    string role = 4;
    repeated int32 assigned_layers = 5;
    map<string, string> capabilities = 6;
    float gpu_utilization = 7;
    float memory_usage_gb = 8;
}

// Tensor message
message Tensor {
    bytes data = 1;
    repeated int64 shape = 2;
    string dtype = 3;
}

// Updated layer request to use Tensor
message LayerRequestV2 {
    Tensor input_tensor = 1;
    int32 start_layer = 2;
    int32 end_layer = 3;
    Tensor attention_mask = 4;  // Optional attention mask
}

// Updated layer response to use Tensor
message LayerResponseV2 {
    Tensor output_tensor = 1;
}

// Forward request
message ForwardRequest {
    repeated int64 input_ids = 1;
    Tensor input_tensor = 2;
    bool is_embedding = 3;
    bool is_final_projection = 4;
    Tensor attention_mask = 5;  // Optional attention mask
}

// Forward response
message ForwardResponse {
    Tensor output = 1;
}

// Health check request/response
message HealthRequest {}

message HealthResponse {
    string status = 1;
    string message = 2;
}