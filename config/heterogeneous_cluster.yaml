# Heterogeneous Cluster Configuration
# Supports capability-based model sharding across devices with different specs

cluster:
  name: "mac-heterogeneous-cluster"
  # Order matters: devices are assigned ranks 0, 1, 2, etc.
  devices:
    - mini1      # Rank 0
    - mini2      # Rank 1  
    - master     # Rank 2 (MacBook Pro)

# Model configuration
model:
  # Model name to load
  name: "mlx-community/Qwen3-1.7B-8bit"
  
  # Sharding strategy:
  # - "equal": Distribute layers equally across devices
  # - "capability_based": Distribute based on compute scores (recommended)
  # - "memory_constrained": Ensure layers fit in available memory
  # - "manual": Use explicit layer_distribution below
  sharding_strategy: "capability_based"
  
  # Optional: Manual layer distribution (used only with "manual" strategy)
  # layer_distribution:
  #   mini1: [0, 1, 2, 3, 4, 5, 6]           # 7 layers (25%)
  #   mini2: [7, 8, 9, 10, 11, 12, 13]       # 7 layers (25%)
  #   master: [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]  # 14 layers (50%)

# Device specifications
# These override auto-detected values
devices:
  mini1:
    hostname: "mini1"
    memory_gb: 16.0
    gpu_cores: 10
    gpu_memory_gb: 12.0    # 75% of system memory for Apple Silicon
    bandwidth_gbps: 10.0   # Thunderbolt 3
    
  mini2:
    hostname: "mini2"
    memory_gb: 16.0
    gpu_cores: 10
    gpu_memory_gb: 12.0
    bandwidth_gbps: 10.0
    
  master:
    hostname: "master"
    memory_gb: 48.0
    gpu_cores: 30         # M2 Max
    gpu_memory_gb: 36.0   # 75% of system memory
    bandwidth_gbps: 10.0

# Communication settings
communication:
  master_addr: "mini1"    # Address of rank 0
  master_port: 29501
  backend: "gloo"         # PyTorch distributed backend
  
# Performance settings
performance:
  # Number of threads per device
  num_threads: 8
  
  # Batch size for inference
  batch_size: 1
  
  # Pipeline settings
  pipeline_parallel: true
  micro_batch_size: 1

# Memory optimization
memory:
  # Use gradient checkpointing to save memory
  gradient_checkpointing: false
  
  # Offload optimizer states to CPU
  cpu_offload: false
  
  # Mixed precision settings
  use_fp16: true
  
# Logging
logging:
  level: "INFO"
  # Log memory usage every N steps
  log_memory_every: 10
  
# Advanced settings
advanced:
  # Warmup steps before benchmarking
  warmup_steps: 3
  
  # Timeout for distributed operations (seconds)
  timeout: 300
  
  # Enable profiling
  enable_profiling: false
  
  # Checkpoint directory (for fault tolerance)
  checkpoint_dir: "./checkpoints"