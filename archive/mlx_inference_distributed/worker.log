2025-08-01 09:35:45,554 - __main__ - INFO - ðŸš€ Starting MLX worker on port 50123
2025-08-01 09:35:46,684 - mlx_discovery - INFO - Registered MLX worker: mini1.local:50123 with 16.0GB RAM, 10 GPU cores
2025-08-01 09:35:46,685 - __main__ - INFO - ðŸ“¡ Registered with discovery service:
2025-08-01 09:35:46,685 - __main__ - INFO -    - Hostname: mini1.local
2025-08-01 09:35:46,685 - __main__ - INFO -    - IP: 192.168.2.13
2025-08-01 09:35:46,685 - __main__ - INFO -    - Port: 50123
2025-08-01 09:35:46,685 - __main__ - INFO -    - Memory: 16.0GB total, 4.4GB available
2025-08-01 09:35:46,685 - __main__ - INFO -    - GPU cores: 10
2025-08-01 09:35:46,685 - __main__ - INFO -    - Thunderbolt: Yes
Traceback (most recent call last):
  File "/Users/mini1/Movies/mlx_inference_distributed/worker_simple.py", line 141, in <module>
    main()
    ~~~~^^
  File "/Users/mini1/Movies/mlx_inference_distributed/worker_simple.py", line 138, in main
    worker.start()
    ~~~~~~~~~~~~^^
  File "/Users/mini1/Movies/mlx_inference_distributed/worker_simple.py", line 65, in start
    config = self._create_worker_config(worker_info)
  File "/Users/mini1/Movies/mlx_inference_distributed/worker_simple.py", line 108, in _create_worker_config
    config = DistributedConfig(
        model_id=self.model_id,
    ...<4 lines>...
        tensor_parallel_size=1
    )
TypeError: DistributedConfig.__init__() got an unexpected keyword argument 'model_id'
